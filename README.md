# Image Scraper for Bear Classification Dataset

## Описание проекта

Image Scraper for Bear Classification Dataset — это инструмент веб-скрейпинга, написанный на Python, предназначенный для автоматического сбора изображений полярных и бурых медведей с Яндекс.Картинок для создания датасета машинного обучения.

Проект реализует собственный алгоритм сбора изображений с использованием Selenium WebDriver и библиотеки OpenCV для валидации изображений. Система включает механизмы обхода защиты от автоматизации, фильтрацию дубликатов и контроль качества загружаемых изображений.

## Основные возможности

- Автоматический сбор изображений для нескольких классов
- Обход механизмов обнаружения ботов
- Фильтрация дубликатов и некорректных изображений
- Поддержка нескольких форматов изображений
- Валидация изображений по размеру и качеству
- Отслеживание времени выполнения операций
- Генерация статистики процесса сбора
- Сохранение результатов в структурированную файловую систему

## Используемые технологии

- Python 3.7+
- Selenium WebDriver
- OpenCV
- NumPy
- Requests
- ChromeDriver

## Архитектура системы

Приложение построено по модульной архитектуре:

- Core Module — основная логика скрейпинга
- Driver Management — управление веб-драйвером
- Image Processing — обработка и валидация изображений
- File System — организация хранения данных
- Statistics Module — сбор и анализ статистики
- Error Handling — обработка исключений

## Конвейер обработки

1. Инициализация веб-драйвера с обходом детектирования
2. Поиск изображений по заданным запросам
3. Прокрутка страницы для подгрузки изображений
4. Извлечение URL изображений из HTML-кода
5. Фильтрация дубликатов и некорректных ссылок
6. Загрузка изображений по URL
7. Валидация изображений по размеру и формату
8. Сохранение в целевую директорию
9. Генерация статистики


## Реализованные алгоритмы

- Алгоритм обхода детектирования автоматизации
- Механизмы парсинга HTML-страниц
- Алгоритмы фильтрации дубликатов
- Валидация изображений по размеру и формату
- Стратегия прокрутки для подгрузки контента
- Обработка сетевых ошибок и таймаутов

## Оценка производительности

В рамках проекта проводится анализ:

- Времени выполнения сбора изображений
- Эффективности поиска URL
- Процента успешных загрузок
- Времени валидации изображений
- Сравнения с и без обхода защиты

## Структура проекта

Проект разделён на следующие компоненты:

- Main Module — основной скрипт выполнения
- Driver Setup — настройка веб-драйвера
- Image Downloader — загрузка и валидация
- Page Scraper — извлечение URL изображений
- File Manager — организация файловой структуры
- Statistics Generator — генерация отчетов

## Назначение проекта

Цель проекта — разработка автоматизированного инструмента для сбора изображений с веб-ресурсов с последующей подготовкой данных для задач машинного обучения, а также исследование эффективности алгоритмов веб-скрейпинга и обхода защитных механизмов.
